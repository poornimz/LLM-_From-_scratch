{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "jwTmwVvr3dBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset ,DataLoader\n",
        "\n",
        "class GPTDatav1(Dataset):\n",
        "  def __init__(self,txt,tokenizer ,max_length ,stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "\n",
        "    token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx] , self.target_ids[idx]"
      ],
      "metadata": {
        "id": "5x-X28tE3fP_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC2tFK-P6K3w",
        "outputId": "12a459cc-6827-4dbc-dd69-26e404d329c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def create_dataloader(txt,batch_size =4 ,\n",
        "                      max_length = 256 ,stride = 128 ,\n",
        "                      shuffle =True,drop_last =True ,\n",
        "                      num_workers = 0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatav1(txt,tokenizer,max_length,stride)\n",
        "  dataloader = DataLoader(dataset,batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "IJHUelGI4o72"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_data = f.read()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bdfzti485WvA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "dataloader = create_dataloader(\n",
        "    raw_data,batch_size=1,max_length=4,stride=1,shuffle = False\n",
        ")\n",
        "\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDnngfyO5lq8",
        "outputId": "cf4d4260-f084-4c9a-9e14-9c6648178d51"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = iter(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C9ayNnz59IN",
        "outputId": "0235aca1-d54e-4a83-815b-765a2c89d0a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7d5a15eb3880>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(\n",
        "    raw_data,batch_size=8,max_length=4,stride=4,shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs,targets =next(data_iter)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TZIxbVA6del",
        "outputId": "7a09041f-9435-4804-aa2f-c46fd42e1752"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Embeddings"
      ],
      "metadata": {
        "id": "aqVHraVF61et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])\n",
        "\n",
        "\n",
        "vocab_size =6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glcAIa-R6vHQ",
        "outputId": "b33328f8-b37f-4ebd-f4c4-470c415045ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGtId6gI7NRt",
        "outputId": "5bd6cd61-6a82-4abe-c059-0131e8d92de8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "bs2JEF-_7dAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim= 256\n",
        "\n",
        "token_embedding_layer =torch.nn.Embedding(vocab_size,output_dim)\n",
        "\n",
        "max_length= 4\n",
        "data_loader = create_dataloader(\n",
        "    raw_data,batch_size=8,max_length=max_length,stride=1,shuffle = False\n",
        ")\n",
        "\n",
        "data_iter =iter(data_loader)\n",
        "inputs,targets = next(data_iter)\n",
        "\n",
        "print(inputs.shape)\n",
        "print(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zemxpPW47bzr",
        "outputId": "a267968d-ed4c-47a7-9958-ef4d095d9f21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4])\n",
            "tensor([[   40,   367,  2885,  1464],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQRFtPTs7rvD",
        "outputId": "004a9b88-4664-4c43-911a-d3d7862dd351"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length,output_dim)\n",
        "\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmKyw2jN8VXW",
        "outputId": "50a6e7ea-e94b-4f9d-9ee6-ae1e069ccf6c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6mAsZNj8omJ",
        "outputId": "a0b51507-bc8c-403b-adfc-83698088d408"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}