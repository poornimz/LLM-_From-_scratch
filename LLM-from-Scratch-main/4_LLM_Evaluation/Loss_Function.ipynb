{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ygiAg_HNn7S5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tndc8zjTn7S-"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hsRS0v5fn7TB"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sfLwTFobn7TD"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self,emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self,x):\n",
        "        mean = x.mean(dim =-1,keepdim =True)\n",
        "        var = x.var(dim =-1 ,keepdim =True)\n",
        "        norm_x = (x-mean)/torch.sqrt(var+self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zktCsBMyn7TE"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in = cfg[\"emb_dim\"],\n",
        "            d_out = cfg[\"emb_dim\"],\n",
        "            context_length = cfg[\"context_length\"],\n",
        "            num_heads = cfg[\"n_heads\"],\n",
        "            dropout = cfg[\"drop_rate\"],\n",
        "            qkv_bias = cfg[\"qkv_bias\"]\n",
        "\n",
        "        )\n",
        "\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PFq4MqnAn7TE"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ouIVkTnWn7TF"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:,-context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:,-1,:]\n",
        "\n",
        "        probas = torch.softmax(logits,dim =-1)\n",
        "\n",
        "        idx_next  = torch.argmax(probas,dim =-1,keepdim =True)\n",
        "\n",
        "        idx = torch.cat((idx,idx_next),dim= -1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8_GjMfyn7TF",
        "outputId": "eb324cc2-1864-4c26-9bb6-29f4dd9c1b20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1rxmi2WobFZ",
        "outputId": "56cf52fd-c8dc-4703-fa63-5eee0c8de819"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHoeP-pQn7TH",
        "outputId": "e8d85bc3-8942-4cde-cf54-0a4955243370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "\n",
        "\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TcwKXjDhn7TM"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVwKk9yhn7TM",
        "outputId": "f998e781-881a-4744-acab-a3a201e23000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4itUVBXWn7TN",
        "outputId": "34f32f31-016b-4c1a-e2fb-2d692913c721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebPFclbcn7TN",
        "outputId": "16b2b483-771b-414e-87e8-e324cb4c0604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7mlklLZn7TO"
      },
      "source": [
        "To Make the performace of LLM Robust , LLM should trained with trainable weights with lossf unctions to update the weights\n",
        "loss Functions used in LLM are Cross Entropy Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stgp0NMxn7TQ",
        "outputId": "a4041d56-87e7-4750-8a6f-9c9dad633c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4514e-05, 3.1054e-05, 1.1567e-05])\n",
            "Text 2: tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSrAcY3on7TR",
        "outputId": "b5ec4290-ff68-45de-8db4-ae206f16faaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5045, -10.3798, -11.3674, -11.4792,  -9.7771, -12.2549])\n"
          ]
        }
      ],
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVOdkpqn7TR",
        "outputId": "9b9ca4bc-52e9-445e-933c-6e092e65cdee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7938)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average probability for each token\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRz1sbMXn7TR",
        "outputId": "e5d2cbaa-347f-41b4-86e6-f56247e7e2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ],
      "source": [
        "# Multiplying the mean term with -1 will provide the loss function to be in positive as log values are negative\n",
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHdXwh5Hn7TS",
        "outputId": "f3e5aabd-0bba-4fa4-eea9-0f1755759117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onEEEQx8n7TS",
        "outputId": "e0a90e19-47b4-42b1-af7a-586b60bfc424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8dJcBqhn7TT",
        "outputId": "ff4a224c-4095-46f7-a070-08fe32a2ef0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Er1oJ98n7TT",
        "outputId": "46e3fbba-ae9c-4431-cb77-ac25f2de6da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48717.6914)\n"
          ]
        }
      ],
      "source": [
        "#Applying torch.exp(loss) might appear in scenarios where you want to undo a logarithmic scale or convert log-probabilities back to the probability domain\n",
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nYNbvSahn7TT",
        "outputId": "dab136f1-ea29-4378-c496-4de9ae46d45d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"/content/the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n",
        "text_data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjHz-Lt0n7TU",
        "outputId": "2d7ca070-e1bc-48ee-e5d4-d48d81a1137d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yVM4SM2Xn7TU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0bCUxF2Rn7TU"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size - No of tokens\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024) - Window size\n",
        "    \"emb_dim\": 768,        # Embedding dimension - Dimension of Each token\n",
        "    \"n_heads\": 12,         # Number of attention heads - No of attention layers in Each transformer Block\n",
        "    \"n_layers\": 12,        # Number of layers - no of transformer blocks\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dIf5rK6Cn7TU"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBLbLLyJn7TU",
        "outputId": "153c4ddf-70e5-425f-f427-8b7089f45804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "9\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvUyROR4n7TU",
        "outputId": "474044d1-8f0f-4a6f-a6ea-8ad3b55df8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HsvG6d2Kn7TV"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqSbhErSn7TV",
        "outputId": "86a5ed0a-2d98-45c0-e9a2-cb42355542e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n",
            "Training loss: 10.987384796142578\n",
            "Validation loss: 10.98090648651123\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEA5WC7vn7TW"
      },
      "source": [
        "<div style=\"background-color:#ffecd2; color:#355c7d; text-align:center; padding:15px; font-size:25px; border-radius:25px; \">LLM PreTraining</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YjF6WwQVn7TW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,\n",
        "eval_freq,eval_iter,start_context,tokenizer):\n",
        "    train_losses , val_losses , track_tokens_seen = [] , [] , []\n",
        "    tokens_seen , global_step = 0, -1\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch , target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step +=1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(model, tokenizer, device,start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vtasiidkn7TX"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GDV_c27rn7TX"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlxByWuRn7TX",
        "outputId": "8e621beb-4cab-4403-d53e-33ab93bee672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.931\n",
            "Ep 1 (Step 000005): Train loss 8.067, Val loss 8.338\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.624, Val loss 7.054\n",
            "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.533, Val loss 6.506\n",
            "Ep 3 (Step 000025): Train loss 5.401, Val loss 6.389\n",
            "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 4.900, Val loss 6.280\n",
            "Ep 4 (Step 000035): Train loss 4.652, Val loss 6.303\n",
            "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 4.030, Val loss 6.166\n",
            "Every effort moves you know                                                 \n",
            "Ep 6 (Step 000045): Train loss 3.630, Val loss 6.172\n",
            "Ep 6 (Step 000050): Train loss 3.051, Val loss 6.145\n",
            "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
            "Ep 7 (Step 000055): Train loss 2.955, Val loss 6.183\n",
            "Ep 7 (Step 000060): Train loss 2.237, Val loss 6.128\n",
            "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
            "Ep 8 (Step 000065): Train loss 1.782, Val loss 6.161\n",
            "Ep 8 (Step 000070): Train loss 1.482, Val loss 6.228\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.141, Val loss 6.267\n",
            "Ep 9 (Step 000080): Train loss 0.864, Val loss 6.296\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Ep 10 (Step 000085): Train loss 0.632, Val loss 6.381\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Training completed in 0.63 minutes.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "yVtw-0PPn7TY",
        "outputId": "7f95735a-ee4f-45ac-d950-81322acd1a14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVHCGbLJn7TY"
      },
      "source": [
        "<div style=\"background-color:#ffecd2; color:#355c7d; text-align:center; padding:15px; font-size:25px; border-radius:25px; \">DECODING STRATEGIES TO CONTROL RANDOMNESS</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJRASpA_n7TY",
        "outputId": "18895a0f-36aa-48c0-ecff-c454442f9305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcK1bKpvn7Tq",
        "outputId": "a145e68a-0051-4625-a95f-fb0dc0e827f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ALpr5-Urn7Ts"
      },
      "outputs": [],
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-1Cq1L9Hn7Tt"
      },
      "outputs": [],
      "source": [
        "next_token_logits = torch.tensor(\n",
        "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "next_token_logits2 = next_token_logits/0.1\n",
        "\n",
        "next_token_logits3 = next_token_logits/5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztvxe00Dn7Tt",
        "outputId": "fbf8ae53-de4c-4968-c67a-0d2bfb91697e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
            "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(next_token_logits2, dim=0)\n",
        "\n",
        "print(probas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EvJVueTn7Tt",
        "outputId": "54347f0b-0bd9-4481-fd29-500e54c2ec2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(next_token_logits3, dim=0)\n",
        "\n",
        "print(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJAkroa-n7Tu",
        "outputId": "dfbd6b46-82c8-4d6e-98e2-281d7b0bc951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
            "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
            "3\n",
            "forward\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "\n",
        "print(probas)\n",
        "\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "\n",
        "print(next_token_id)\n",
        "\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioXWSk_dn7Tu",
        "outputId": "af749e15-573b-4365-cf53-dc3f42d6823b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5oK0G6pn7Tu",
        "outputId": "d8ccfc99-3556-4125-ce70-160bcfb0f178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "544 x forward\n",
            "2 x inches\n",
            "1 x moves\n",
            "0 x pizza\n",
            "376 x toward\n",
            "4 x you\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "N5Kenv3Sn7Tv"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "temperatures = [1, 0.1, 5]\n",
        "\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "D2F6Hg4tn7Tv",
        "outputId": "ef43af41-1c3f-48f1-9518-c5e93335294e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2bmrn0xn7Tv"
      },
      "source": [
        "<div style=\"background-color:#ffecd2; color:#355c7d; text-align:center; padding:15px; font-size:25px; border-radius:25px; \">DECODING STRATEGY 2: Top-k sampling</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfcdFmUZn7Tv",
        "outputId": "9d28976c-859d-4e45-d350-435e118134f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3itL3Uv6n7Tw",
        "outputId": "047fc3fd-ed54-4fdd-ad6a-dcd6caec4abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ],
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBFrwhOwn7Tw",
        "outputId": "3a6b7f5b-46bb-49c3-bbc9-ea500ad61db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "stDhTqk-n7Tw"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3GfcWkgn7Tw",
        "outputId": "606a3e74-e393-4498-9784-5f6e1c005e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know began to go a little wild--I was such a good; and\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "pKRa1DvNt1Oe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExLPoOgcuCnX",
        "outputId": "a571f7cf-dc9d-44a1-a871-4632729bfa01"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-f3ec32668201>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "RV_TdZqaukFJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcY30byVul8D",
        "outputId": "5df0a3b2-748e-475c-b80e-5fcba8d9f6ba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-463cac8a72b4>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"model_and_optimizer.pth\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " LOADING PRETRAINED WEIGHTS FROM OPENAI"
      ],
      "metadata": {
        "id": "kpn2a1lNupq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "lV3pl5wIunIz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_file(url, destination):\n",
        "    \"\"\"Download a file from a URL and save it to a destination.\"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
        "    with open(destination, 'wb') as f, tqdm(\n",
        "        desc=destination.split(\"/\")[-1], total=total_size, unit='iB', unit_scale=True\n",
        "    ) as pbar:\n",
        "        for data in response.iter_content(chunk_size=1024):\n",
        "            pbar.update(len(data))\n",
        "            f.write(data)\n",
        "\n",
        "def download_gpt2_files(model_size, target_dir):\n",
        "    \"\"\"Download GPT-2 model files from OpenAI.\"\"\"\n",
        "    base_url = f\"https://openaipublic.blob.core.windows.net/gpt-2/models/{model_size}/\"\n",
        "    files = [\n",
        "        \"checkpoint\",\n",
        "        \"encoder.json\",\n",
        "        \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\",\n",
        "        \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\",\n",
        "        \"vocab.bpe\",\n",
        "    ]\n",
        "\n",
        "    for file in files:\n",
        "        url = base_url + file\n",
        "        destination = os.path.join(target_dir, model_size, file)\n",
        "        download_file(url, destination)\n",
        "\n",
        "# Set parameters\n",
        "model_size = \"124M\"  # Options: \"124M\", \"355M\", \"774M\", \"1558M\"\n",
        "target_dir = \"/content/gpt2\"  # Local directory in Colab to save files\n",
        "\n",
        "# Download the model files\n",
        "download_gpt2_files(model_size, target_dir)\n",
        "print(f\"GPT-2 model files for {model_size} downloaded to {target_dir}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvDXxjd2wNSq",
        "outputId": "772ff079-4025-425b-efdf-8c48e91134ef"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 63.5kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 562kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 362kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:21<00:00, 6.13MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 7.06MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 336kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 278kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2 model files for 124M downloaded to /content/gpt2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "    return params\n",
        "\n",
        "def load_gpt2_weights(model_dir):\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    if not tf_ckpt_path:\n",
        "        raise FileNotFoundError(f\"Checkpoint not found in {model_dir}\")\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "    return settings, params\n",
        "\n",
        "# Set model directory\n",
        "model_dir = os.path.join(target_dir, model_size)\n",
        "\n",
        "# Load weights\n",
        "settings, params = load_gpt2_weights(model_dir)\n",
        "\n",
        "# Verify loaded settings and parameters\n",
        "print(\"Settings:\", settings)\n",
        "print(\"Number of blocks:\", len(params['blocks']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF8GTEvA3fpt",
        "outputId": "eea466dc-49ba-42ae-c566-c7a569ab3884"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Number of blocks: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"tqdm version:\", tqdm.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfcHvRFGurwH",
        "outputId": "5edabb60-1855-4534-9230-d19c1d520f00"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.1\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X9YIwF8uw7j",
        "outputId": "061de4e0-e3ba-40be-f229-49043f4be1fa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UhsQtlzu9e-",
        "outputId": "0ce9f2a7-f11f-402a-86fc-0801b04ea67f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n"
      ],
      "metadata": {
        "id": "2uvI_qffu_bn"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "5wVF3XylvBCD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "lVzF80ArvGuI"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "aVrLEOX6vIsN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "25ioDVOC5VJ3"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpWMxi1u5YHR",
        "outputId": "2fde92e5-6154-44f7-aab5-18f2dcae8f9e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you as far as the hand can go until the end of your turn. By now there's a very small delay before you gain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"What is Machine Learning\", tokenizer).to(device),\n",
        "    max_new_tokens=1000,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopX6xQg8nJH",
        "outputId": "f77bae82-5f3e-472a-e1a6-82170013fffb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " What is Machine Learning as we speak – can you explain how the word \"learning data theory\" works?\"\n",
            "\n",
            "Kasikasou: Oh yeah so basically everything I talk about on there is based on some kind of machine learning model. I am talking about the kinds of assumptions machine learning and semantic machine learning can make in some sense. They all talk about machine learning's ability to learn more. If a training problem is one that has problems where a machine learning model can handle things more reasonably than machine learning does a trained approach won't learn as much at first without training. That's one difference between this one way of thinking. When you talk about the power of machine learning to solve problems like this training problem, this problem only actually improves if machine learning was trained to do it better. In fact machine learning will even make some improvements in this problem if training is trained better, maybe even before or during training sessions. Machine Learning has these kind of limitations and limitations like when somebody can get really close to an agent, that you don't know what they are. But these limitations are pretty important for the reason I am addressing machine learning. Machine learning is hard to understand, because machine learning doesn't understand that it's being done, like is how you go up, just look, look at one thing to get close to an agent like what you could do is maybe check whether this person was doing it correctly, if you put a bunch of data into a machine, what happens is instead of checking some random bit to see if this person was doing that correctly when you put other bit, this machine just starts going, looking at everything else.\n",
            "\n",
            "I am talking about the power of machine learning which I know is not exactly there, because I was going to do another piece on AI which isn't on the same scale of machines being done differently, because machine learning doesn't actually have that specific mechanism where they just look at something to see what sort of things are making an interaction in the situation before they think, where it doesn't matter to machines who are good at this at trying, if it is this situation and machine learning does this good, but I'm just really confused with it now, that it's always this sort of case when you think about a specific situation. What, if it were just this problem a machine trying out some of their inputs, like we saw in the beginning of the game? It wasn't even like that, you try and look for certain things before doing action and you go through that but sometimes a good machine is actually really good at thinking at what's what before it goes and it actually works up a whole series of different ways to give you specific patterns. You go through how an action moves but you won't find what's happening immediately until you know what you know is happening. Which I'm really confused with, and what I was actually talking about was people looking at that same problem with machine learning as to how do AI go about getting that way then, like is that what human reasoning is then but the way you're interested in it at the time is how are its being used to make decisions and you actually do that in order to build better decisions but machine learning does get used like these things you could make that are not already there. There's a certain problem now where what I'm working on here is actually figuring out how all of these ideas relate to make sure to think outside the box in the situation at hand, with some very basic assumptions in order to not take yourself too seriously, as you can see below and I've done that really well in the end with my work.\n",
            "\n",
            "Now as an aside from the one, I mean maybe if Google were to ask you – when you get to know someone better then not just be happy your life might improve too much with the Google acquisition then what do you do in order to get a good start making money then what you should do after?\n",
            "\n",
            "Kasikasou: Well, what I would do then maybe would be if they asked about me, who do what, maybe even my friend I didn't do it and then after talking to him at work on something with the people at their company you go, if he finds that out then you need to keep doing it and hopefully find that eventually get people to care what's going on too but I guess the important thing is to try not to put a too much spotlight on yourself, because it shouldn't affect yourself but look who is going to keep coming back that eventually they make good. I just don't think Google has the talent or skill required on the platform like to really go back. I did talk with the right man on why that's how he has it and he would probably help me find that and if maybe this is going to be my personal role and perhaps I can then come up with something similar to my mentor but again you work really hard to do well at doing well that allows you to understand different kinds of\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}